{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7832335,"sourceType":"datasetVersion","datasetId":4533177}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-15T12:00:27.078299Z","iopub.execute_input":"2024-03-15T12:00:27.079129Z","iopub.status.idle":"2024-03-15T12:00:27.907386Z","shell.execute_reply.started":"2024-03-15T12:00:27.079094Z","shell.execute_reply":"2024-03-15T12:00:27.906505Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ecg-data/CWT.py\n/kaggle/input/ecg-data/check_preproc_df\n/kaggle/input/ecg-data/VECG.py\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install neurokit2","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:27.909393Z","iopub.execute_input":"2024-03-15T12:00:27.909843Z","iopub.status.idle":"2024-03-15T12:00:41.635937Z","shell.execute_reply.started":"2024-03-15T12:00:27.909811Z","shell.execute_reply":"2024-03-15T12:00:41.634858Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting neurokit2\n  Downloading neurokit2-0.2.7-py2.py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from neurokit2) (2.1.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.11.4)\nRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from neurokit2) (3.7.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (3.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\nDownloading neurokit2-0.2.7-py2.py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: neurokit2\nSuccessfully installed neurokit2-0.2.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import Subset\nfrom torch.utils.data import TensorDataset\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport sys\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:41.637359Z","iopub.execute_input":"2024-03-15T12:00:41.637655Z","iopub.status.idle":"2024-03-15T12:00:49.013762Z","shell.execute_reply.started":"2024-03-15T12:00:41.637626Z","shell.execute_reply":"2024-03-15T12:00:49.012984Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Подгружаем пути к директориям с нашими алгоритмами:\ncur_dir = os.getcwd()\nwavelets_path = os.path.join(cur_dir, \"../input/ecg-data/\")\nscript_path = os.path.join(cur_dir, \"../input/ecg-data/\")\nprint(script_path)\nprint(wavelets_path)\nsys.path.append(wavelets_path)\nsys.path.append(script_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:49.014747Z","iopub.execute_input":"2024-03-15T12:00:49.015131Z","iopub.status.idle":"2024-03-15T12:00:49.021052Z","shell.execute_reply.started":"2024-03-15T12:00:49.015107Z","shell.execute_reply":"2024-03-15T12:00:49.020168Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/../input/ecg-data/\n/kaggle/working/../input/ecg-data/\n","output_type":"stream"}]},{"cell_type":"code","source":"# Подгружаем алгоритмы для подготовки данных:\nimport VECG as vecg # Алгоритмы для формирования векторного представления кардиоциклов\nimport CWT as wt # Алгоритмы для вейвлет преобразования графиков ЭКГ","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:49.024174Z","iopub.execute_input":"2024-03-15T12:00:49.024754Z","iopub.status.idle":"2024-03-15T12:00:50.094977Z","shell.execute_reply.started":"2024-03-15T12:00:49.024722Z","shell.execute_reply":"2024-03-15T12:00:50.094245Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_size = 1000","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:50.096037Z","iopub.execute_input":"2024-03-15T12:00:50.096612Z","iopub.status.idle":"2024-03-15T12:00:50.100875Z","shell.execute_reply.started":"2024-03-15T12:00:50.096578Z","shell.execute_reply":"2024-03-15T12:00:50.099851Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ECG_df = pd.read_pickle('/kaggle/input/ecg-data/check_preproc_df')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:50.102458Z","iopub.execute_input":"2024-03-15T12:00:50.103063Z","iopub.status.idle":"2024-03-15T12:00:58.835685Z","shell.execute_reply.started":"2024-03-15T12:00:50.103029Z","shell.execute_reply":"2024-03-15T12:00:58.834622Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ECG_df = ECG_df[0:2*data_size]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:58.837060Z","iopub.execute_input":"2024-03-15T12:00:58.837496Z","iopub.status.idle":"2024-03-15T12:00:58.842245Z","shell.execute_reply.started":"2024-03-15T12:00:58.837463Z","shell.execute_reply":"2024-03-15T12:00:58.841350Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"vecg.init(filtering=True, canc_showing=True, plot3D=False, enable_centering = True, enable_local_normalize=True)\nECG_df = vecg.make_vecg_df(ECG_df, 0, 2)\nECG_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:00:58.843401Z","iopub.execute_input":"2024-03-15T12:00:58.843980Z","iopub.status.idle":"2024-03-15T12:09:48.375601Z","shell.execute_reply.started":"2024-03-15T12:00:58.843949Z","shell.execute_reply":"2024-03-15T12:09:48.374626Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Я в процессе\nЯ кончил\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   data label  \\\n855   [[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.024, 0...    AF   \n1523  [[-0.015, -0.015, -0.015, -0.015, -0.015, -0.0...    SR   \n80    [[0.095, 0.095, 0.095, 0.095, 0.095, 0.095, 0....    AF   \n593   [[-0.195, -0.195, -0.195, -0.195, -0.195, -0.1...    AF   \n1145  [[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0...    SR   \n\n                                                     XY  \\\n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n\n                                                     YZ  \\\n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n\n                                                     ZX  \n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>label</th>\n      <th>XY</th>\n      <th>YZ</th>\n      <th>ZX</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>855</th>\n      <td>[[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.024, 0...</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1523</th>\n      <td>[[-0.015, -0.015, -0.015, -0.015, -0.015, -0.0...</td>\n      <td>SR</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>[[0.095, 0.095, 0.095, 0.095, 0.095, 0.095, 0....</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>[[-0.195, -0.195, -0.195, -0.195, -0.195, -0.1...</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1145</th>\n      <td>[[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0...</td>\n      <td>SR</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def binarize(X):\n    for i, row in X.iterrows():\n        X.at[i, \"XY\"][X.at[i, \"XY\"] == 255] = 0\n        X.at[i, \"XY\"][X.at[i, \"XY\"] != 0] = 1\n        \n        X.at[i, \"YZ\"][X.at[i, \"YZ\"] == 255] = 0\n        X.at[i, \"YZ\"][X.at[i, \"YZ\"] != 0] = 1\n        \n        X.at[i, \"ZX\"][X.at[i, \"ZX\"] == 255] = 0\n        X.at[i, \"ZX\"][X.at[i, \"ZX\"] != 0] = 1\n            ","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:09:48.376773Z","iopub.execute_input":"2024-03-15T12:09:48.377061Z","iopub.status.idle":"2024-03-15T12:09:48.383903Z","shell.execute_reply.started":"2024-03-15T12:09:48.377036Z","shell.execute_reply":"2024-03-15T12:09:48.382950Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import gc\ndef transform(X):\n    #for i in range(X.shape[1]):\n    X[0][:] = X[0][:] - 0.485\n    X[1][:] = X[1][:] - 0.456\n    X[2][:] = X[2][:] - 0.406\n        \n    X[0][:] = X[0][:] / 0.229\n    X[1][:] = X[1][:] / 0.224\n    X[2][:] = X[2][:] / 0.225\n    gc.collect()\n    return X","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:09:48.385005Z","iopub.execute_input":"2024-03-15T12:09:48.385293Z","iopub.status.idle":"2024-03-15T12:09:48.396362Z","shell.execute_reply.started":"2024-03-15T12:09:48.385270Z","shell.execute_reply":"2024-03-15T12:09:48.395545Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"binarize(ECG_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:09:48.397540Z","iopub.execute_input":"2024-03-15T12:09:48.398110Z","iopub.status.idle":"2024-03-15T12:09:55.350156Z","shell.execute_reply.started":"2024-03-15T12:09:48.398080Z","shell.execute_reply":"2024-03-15T12:09:55.349376Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#transform(ECG_df)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:09:55.351157Z","iopub.execute_input":"2024-03-15T12:09:55.351475Z","iopub.status.idle":"2024-03-15T12:10:05.415454Z","shell.execute_reply.started":"2024-03-15T12:09:55.351450Z","shell.execute_reply":"2024-03-15T12:10:05.414422Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"12732000"},"metadata":{}}]},{"cell_type":"code","source":"# Формируем непосредственно набор данных и меток:\nX_ECG = np.array([ECG_df.iloc[:,2].tolist(),\n                 ECG_df.iloc[:,3].tolist(),\n                 ECG_df.iloc[:,4].tolist()])\nX_ECG = X_ECG.astype(\"float32\")\nX_ECG = transform(X_ECG)\nX_ECG = np.transpose(X_ECG, (1, 2, 3, 0))\n#X_ECG[X_ECG == 255 ] = 0\n#X_ECG[X_ECG != 0] = 1\ny_ECG = np.array(ECG_df.iloc[:,1].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:05.449911Z","iopub.execute_input":"2024-03-15T12:10:05.450241Z","iopub.status.idle":"2024-03-15T12:10:19.958999Z","shell.execute_reply.started":"2024-03-15T12:10:05.450191Z","shell.execute_reply":"2024-03-15T12:10:19.958248Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Производим деление выборки на тренировочную и тестовую\nX_train, X_test = (X_ECG[:int(data_size *10/11)*2], X_ECG[int(data_size *10/11)*2:data_size*2])\ny_train, y_test = (y_ECG[:int(data_size *10/11)*2], y_ECG[int(data_size *10/11)*2:data_size*2])\n\nX_ECG = 0\ny_ECG = 0\ngc.collect()\n\nX_val, y_val = X_train[:int(data_size * 1/10) * 2], y_train[:int(data_size * 1/10) * 2]\nX_train, y_train = X_train[int(data_size * 1/10) * 2:], y_train[int(data_size * 1/10) * 2:]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:19.960183Z","iopub.execute_input":"2024-03-15T12:10:19.960536Z","iopub.status.idle":"2024-03-15T12:10:20.143458Z","shell.execute_reply.started":"2024-03-15T12:10:19.960504Z","shell.execute_reply":"2024-03-15T12:10:20.142439Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train = np.transpose(X_train, (0, 3, 1, 2 ))\nX_test = np.transpose(X_test, (0, 3, 1, 2))\nX_val = np.transpose(X_val, (0, 3, 1, 2))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.144667Z","iopub.execute_input":"2024-03-15T12:10:20.144990Z","iopub.status.idle":"2024-03-15T12:10:20.157332Z","shell.execute_reply.started":"2024-03-15T12:10:20.144965Z","shell.execute_reply":"2024-03-15T12:10:20.156138Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Нормируем данные\n# X_train = X_train.astype('float32')\n# X_test = X_test.astype('float32')\n# X_val = X_val.astype('float32')\n# X_train = X_train / 255.0 * 0.99 + 0.01\n# X_test = X_test / 255.0 * 0.99 + 0.01","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.158356Z","iopub.execute_input":"2024-03-15T12:10:20.158647Z","iopub.status.idle":"2024-03-15T12:10:20.173235Z","shell.execute_reply.started":"2024-03-15T12:10:20.158623Z","shell.execute_reply":"2024-03-15T12:10:20.172408Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y_train = np.array([1 if label == \"SR\" else 0 for label in y_train])\ny_test = np.array([1 if label == \"SR\" else 0 for label in y_test])\ny_val = np.array([1 if label == \"SR\" else 0 for label in y_val])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.174298Z","iopub.execute_input":"2024-03-15T12:10:20.174554Z","iopub.status.idle":"2024-03-15T12:10:20.185261Z","shell.execute_reply.started":"2024-03-15T12:10:20.174532Z","shell.execute_reply":"2024-03-15T12:10:20.184464Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# # Производим энкодинг полученных меток классов в удобный для обработки сетью вид\n# print('Метка класса перед энкодингом:', y_train[:10])\n# encoder = OneHotEncoder()\n# encoder.fit(y_train.reshape(-1, 1))\n# y_train = encoder.transform(y_train.reshape(-1, 1)).toarray()\n# y_test = encoder.transform(y_test.reshape(-1, 1)).toarray()\n# y_val = encoder.transform(y_val.reshape(-1, 1)).toarray()\n# print('Метка класса после энкодинга:', y_train[:10])\n# encoder.categories_","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.186968Z","iopub.execute_input":"2024-03-15T12:10:20.187699Z","iopub.status.idle":"2024-03-15T12:10:20.195112Z","shell.execute_reply.started":"2024-03-15T12:10:20.187673Z","shell.execute_reply":"2024-03-15T12:10:20.194346Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.196244Z","iopub.execute_input":"2024-03-15T12:10:20.196508Z","iopub.status.idle":"2024-03-15T12:10:20.205474Z","shell.execute_reply.started":"2024-03-15T12:10:20.196485Z","shell.execute_reply":"2024-03-15T12:10:20.204638Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(1618,)\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.206475Z","iopub.execute_input":"2024-03-15T12:10:20.206739Z","iopub.status.idle":"2024-03-15T12:10:20.390300Z","shell.execute_reply.started":"2024-03-15T12:10:20.206716Z","shell.execute_reply":"2024-03-15T12:10:20.389390Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# Создание Dataset и DataLoader\ntrain_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ntest_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\nval_dataset = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.391503Z","iopub.execute_input":"2024-03-15T12:10:20.391881Z","iopub.status.idle":"2024-03-15T12:10:20.410624Z","shell.execute_reply.started":"2024-03-15T12:10:20.391846Z","shell.execute_reply":"2024-03-15T12:10:20.409840Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X_train = 0\nX_test = 0\nX_val = 0\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.411708Z","iopub.execute_input":"2024-03-15T12:10:20.411981Z","iopub.status.idle":"2024-03-15T12:10:20.586444Z","shell.execute_reply.started":"2024-03-15T12:10:20.411957Z","shell.execute_reply":"2024-03-15T12:10:20.585469Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 15\n\ntrain_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True)\nval_dataloader = DataLoader(val_dataset, batch_size, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.587698Z","iopub.execute_input":"2024-03-15T12:10:20.587968Z","iopub.status.idle":"2024-03-15T12:10:20.596421Z","shell.execute_reply.started":"2024-03-15T12:10:20.587945Z","shell.execute_reply":"2024-03-15T12:10:20.595617Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#googlenet = torchvision.models.googlenet(pretrained=True)\nresnet18 = torchvision.models.resnet18(pretrained=True)\nmodel = resnet18","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:20.597500Z","iopub.execute_input":"2024-03-15T12:10:20.597785Z","iopub.status.idle":"2024-03-15T12:10:21.416351Z","shell.execute_reply.started":"2024-03-15T12:10:20.597761Z","shell.execute_reply":"2024-03-15T12:10:21.415444Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 114MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:21.417695Z","iopub.execute_input":"2024-03-15T12:10:21.417975Z","iopub.status.idle":"2024-03-15T12:10:21.670135Z","shell.execute_reply.started":"2024-03-15T12:10:21.417950Z","shell.execute_reply":"2024-03-15T12:10:21.669273Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:21.671597Z","iopub.execute_input":"2024-03-15T12:10:21.671882Z","iopub.status.idle":"2024-03-15T12:10:21.853990Z","shell.execute_reply.started":"2024-03-15T12:10:21.671857Z","shell.execute_reply":"2024-03-15T12:10:21.852982Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch\nimport torch.nn as nn\n\nclass InceptionBlock(nn.Module):\n    def __init__(self, in_channels, out1x1, red3x3, out3x3, red5x5, out5x5, out1x1pool):\n        super(InceptionBlock, self).__init__()\n        # 1x1 convolution\n        self.branch1x1 = nn.Conv2d(in_channels, out1x1, kernel_size=1)\n\n        # 1x1 convolution followed by 3x3 convolution\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, red3x3, kernel_size=1),\n            nn.Conv2d(red3x3, out3x3, kernel_size=3, padding=1)\n        )\n\n        # 1x1 convolution followed by 5x5 convolution\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, red5x5, kernel_size=1),\n            nn.Conv2d(red5x5, out5x5, kernel_size=5, padding=2)\n        )\n\n        # 3x3 max pooling followed by 1x1 convolution\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, out1x1pool, kernel_size=1)\n        )\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n\n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass GoogLeNet(nn.Module):\n    def __init__(self, num_classes=2):\n        super(GoogLeNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Inception blocks\n        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n\n        # Global average pooling\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n        # Fully connected layer\n        self.fc = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = self.maxpool2(F.relu(self.conv2(x)))\n        x = self.maxpool3(self.inception3a(x))\n        x = self.maxpool4(self.inception4e(self.inception4d(self.inception4c(self.inception4b(self.inception4a(x))))))\n        x = self.inception5b(self.inception5a(x))\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:21.855495Z","iopub.execute_input":"2024-03-15T12:10:21.855821Z","iopub.status.idle":"2024-03-15T12:10:21.876724Z","shell.execute_reply.started":"2024-03-15T12:10:21.855796Z","shell.execute_reply":"2024-03-15T12:10:21.875717Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\n\nclass FocalLoss(nn.Module):\n    \"Focal loss implemented using F.cross_entropy\"\n    def __init__(self, gamma: float = 2.0, weight=None, reduction: str = 'mean') -> None:\n        super().__init__()\n        self.gamma = gamma\n        self.weight = weight\n        self.reduction = reduction\n\n\n    def forward(self, inp: torch.Tensor, targ: torch.Tensor):\n        ce_loss = F.cross_entropy(inp, targ, weight=self.weight, reduction=\"none\")\n        p_t = torch.exp(-ce_loss)\n        loss = (1 - p_t)**self.gamma * ce_loss\n        if self.reduction == \"mean\":\n            loss = loss.mean()\n        elif self.reduction == \"sum\":\n            loss = loss.sum()\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:10:21.877972Z","iopub.execute_input":"2024-03-15T12:10:21.878436Z","iopub.status.idle":"2024-03-15T12:10:21.891296Z","shell.execute_reply.started":"2024-03-15T12:10:21.878402Z","shell.execute_reply":"2024-03-15T12:10:21.890457Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#googlenet = GoogLeNet(num_classes = 2)\n#Changing the last fc to 4 output features\n#GoogLeNet.fc = torch.nn.Linear(in_features=512, out_features=4)\n# Заменяем последний fully connected слой для задачи классификации\nnum_classes = 2  # Замените на количество классов в вашей задаче\nmodel.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n\ncriterion = torch.nn.CrossEntropyLoss()\n#criterion = FocalLoss()\n\noptimizer = torch.optim.ASGD(model.parameters(), lr=3e-4)\n#optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n#optimizer = optim.LBFGS(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:19:48.219366Z","iopub.execute_input":"2024-03-15T12:19:48.220107Z","iopub.status.idle":"2024-03-15T12:19:48.226861Z","shell.execute_reply.started":"2024-03-15T12:19:48.220077Z","shell.execute_reply":"2024-03-15T12:19:48.225944Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, criterion, device):\n    model.eval()  # Переводим модель в режим оценки (без обновления весов)\n\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for val_step, (images, labels) in enumerate(dataloader):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / total\n    print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n\n    model.train()  # Возвращаем модель в режим обучения","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:19:51.536971Z","iopub.execute_input":"2024-03-15T12:19:51.537352Z","iopub.status.idle":"2024-03-15T12:19:51.544851Z","shell.execute_reply.started":"2024-03-15T12:19:51.537322Z","shell.execute_reply":"2024-03-15T12:19:51.543847Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs):\n    print('Starting training..')\n    for e in range(0, epochs):\n        print('='*20)\n        print(f'Starting epoch {e + 1}/{epochs}')\n        print('='*20)\n\n        train_loss = 0.\n        val_loss = 0.  # Not computing val_loss since we'll be evaluating the model multiple times within one epoch\n        \n        model.train() # set model to training phase\n        model.to(device)\n        \n        for train_step, (images, labels) in enumerate(train_dataloader):\n            optimizer.zero_grad()\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            # Once we get the loss we need to take a gradient step\n            loss.backward() # Back propagation\n            optimizer.step() # Completes the gradient step by updating all the parameter values (we are using all parameters)\n            train_loss += loss.item() # Loss is a tensor which can't be added to train_loss so .item() converts it to float\n               \n\n        train_loss /= (train_step + 1)\n\n        print(f'Training Loss: {train_loss:.4f}')\n        validate(model, val_dataloader, criterion, device)\n    print('Training complete..')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:19:53.396583Z","iopub.execute_input":"2024-03-15T12:19:53.397473Z","iopub.status.idle":"2024-03-15T12:19:53.405454Z","shell.execute_reply.started":"2024-03-15T12:19:53.397438Z","shell.execute_reply":"2024-03-15T12:19:53.404469Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntrain(model=model, epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:19:56.747876Z","iopub.execute_input":"2024-03-15T12:19:56.748551Z","iopub.status.idle":"2024-03-15T12:35:17.504558Z","shell.execute_reply.started":"2024-03-15T12:19:56.748514Z","shell.execute_reply":"2024-03-15T12:35:17.503378Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Starting training..\n====================\nStarting epoch 1/50\n====================\nTraining Loss: 0.6858\nValidation Accuracy: 53.50%\n====================\nStarting epoch 2/50\n====================\nTraining Loss: 0.6726\nValidation Accuracy: 60.00%\n====================\nStarting epoch 3/50\n====================\nTraining Loss: 0.6620\nValidation Accuracy: 60.50%\n====================\nStarting epoch 4/50\n====================\nTraining Loss: 0.6527\nValidation Accuracy: 61.50%\n====================\nStarting epoch 5/50\n====================\nTraining Loss: 0.6441\nValidation Accuracy: 60.50%\n====================\nStarting epoch 6/50\n====================\nTraining Loss: 0.6359\nValidation Accuracy: 62.50%\n====================\nStarting epoch 7/50\n====================\nTraining Loss: 0.6282\nValidation Accuracy: 63.00%\n====================\nStarting epoch 8/50\n====================\nTraining Loss: 0.6206\nValidation Accuracy: 64.50%\n====================\nStarting epoch 9/50\n====================\nTraining Loss: 0.6133\nValidation Accuracy: 64.00%\n====================\nStarting epoch 10/50\n====================\nTraining Loss: 0.6063\nValidation Accuracy: 65.00%\n====================\nStarting epoch 11/50\n====================\nTraining Loss: 0.5993\nValidation Accuracy: 65.50%\n====================\nStarting epoch 12/50\n====================\nTraining Loss: 0.5926\nValidation Accuracy: 66.50%\n====================\nStarting epoch 13/50\n====================\nTraining Loss: 0.5858\nValidation Accuracy: 65.50%\n====================\nStarting epoch 14/50\n====================\nTraining Loss: 0.5791\nValidation Accuracy: 64.50%\n====================\nStarting epoch 15/50\n====================\nTraining Loss: 0.5726\nValidation Accuracy: 65.50%\n====================\nStarting epoch 16/50\n====================\nTraining Loss: 0.5661\nValidation Accuracy: 65.50%\n====================\nStarting epoch 17/50\n====================\nTraining Loss: 0.5598\nValidation Accuracy: 65.50%\n====================\nStarting epoch 18/50\n====================\nTraining Loss: 0.5535\nValidation Accuracy: 66.00%\n====================\nStarting epoch 19/50\n====================\nTraining Loss: 0.5472\nValidation Accuracy: 66.00%\n====================\nStarting epoch 20/50\n====================\nTraining Loss: 0.5411\nValidation Accuracy: 66.00%\n====================\nStarting epoch 21/50\n====================\nTraining Loss: 0.5349\nValidation Accuracy: 66.00%\n====================\nStarting epoch 22/50\n====================\nTraining Loss: 0.5288\nValidation Accuracy: 66.00%\n====================\nStarting epoch 23/50\n====================\nTraining Loss: 0.5228\nValidation Accuracy: 66.50%\n====================\nStarting epoch 24/50\n====================\nTraining Loss: 0.5168\nValidation Accuracy: 66.50%\n====================\nStarting epoch 25/50\n====================\nTraining Loss: 0.5108\nValidation Accuracy: 67.00%\n====================\nStarting epoch 26/50\n====================\nTraining Loss: 0.5048\nValidation Accuracy: 67.00%\n====================\nStarting epoch 27/50\n====================\nTraining Loss: 0.4988\nValidation Accuracy: 67.50%\n====================\nStarting epoch 28/50\n====================\nTraining Loss: 0.4928\nValidation Accuracy: 68.00%\n====================\nStarting epoch 29/50\n====================\nTraining Loss: 0.4868\nValidation Accuracy: 68.00%\n====================\nStarting epoch 30/50\n====================\nTraining Loss: 0.4807\nValidation Accuracy: 67.00%\n====================\nStarting epoch 31/50\n====================\nTraining Loss: 0.4746\nValidation Accuracy: 67.00%\n====================\nStarting epoch 32/50\n====================\nTraining Loss: 0.4684\nValidation Accuracy: 67.00%\n====================\nStarting epoch 33/50\n====================\nTraining Loss: 0.4622\nValidation Accuracy: 67.50%\n====================\nStarting epoch 34/50\n====================\nTraining Loss: 0.4559\nValidation Accuracy: 67.50%\n====================\nStarting epoch 35/50\n====================\nTraining Loss: 0.4495\nValidation Accuracy: 67.00%\n====================\nStarting epoch 36/50\n====================\nTraining Loss: 0.4430\nValidation Accuracy: 66.50%\n====================\nStarting epoch 37/50\n====================\nTraining Loss: 0.4365\nValidation Accuracy: 65.00%\n====================\nStarting epoch 38/50\n====================\nTraining Loss: 0.4299\nValidation Accuracy: 65.00%\n====================\nStarting epoch 39/50\n====================\nTraining Loss: 0.4232\nValidation Accuracy: 65.00%\n====================\nStarting epoch 40/50\n====================\nTraining Loss: 0.4164\nValidation Accuracy: 64.50%\n====================\nStarting epoch 41/50\n====================\nTraining Loss: 0.4095\nValidation Accuracy: 65.00%\n====================\nStarting epoch 42/50\n====================\nTraining Loss: 0.4025\nValidation Accuracy: 65.00%\n====================\nStarting epoch 43/50\n====================\nTraining Loss: 0.3954\nValidation Accuracy: 65.00%\n====================\nStarting epoch 44/50\n====================\nTraining Loss: 0.3882\nValidation Accuracy: 65.00%\n====================\nStarting epoch 45/50\n====================\nTraining Loss: 0.3808\nValidation Accuracy: 65.00%\n====================\nStarting epoch 46/50\n====================\nTraining Loss: 0.3734\nValidation Accuracy: 65.00%\n====================\nStarting epoch 47/50\n====================\nTraining Loss: 0.3659\nValidation Accuracy: 64.50%\n====================\nStarting epoch 48/50\n====================\nTraining Loss: 0.3583\nValidation Accuracy: 64.00%\n====================\nStarting epoch 49/50\n====================\nTraining Loss: 0.3506\nValidation Accuracy: 64.00%\n====================\nStarting epoch 50/50\n====================\nTraining Loss: 0.3428\nValidation Accuracy: 64.00%\nTraining complete..\nCPU times: user 15min 52s, sys: 2min 52s, total: 18min 44s\nWall time: 15min 20s\n","output_type":"stream"}]},{"cell_type":"code","source":"def test(model, dataloader, criterion, device):\n    model.eval()  # Переводим модель в режим оценки (без обновления весов)\n\n    correct = 0\n    total = 0\n    y_pred = []\n\n    with torch.no_grad():\n        for val_step, (images, labels) in enumerate(dataloader):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            y_pred.extend(predicted.cpu().numpy())\n    accuracy = correct / total\n    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n\n    model.train()  # Возвращаем модель в режим обучения\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:35:17.506177Z","iopub.execute_input":"2024-03-15T12:35:17.506479Z","iopub.status.idle":"2024-03-15T12:35:17.513866Z","shell.execute_reply.started":"2024-03-15T12:35:17.506454Z","shell.execute_reply":"2024-03-15T12:35:17.512857Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"y_pred_test = test(model, test_dataloader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:35:17.515149Z","iopub.execute_input":"2024-03-15T12:35:17.515813Z","iopub.status.idle":"2024-03-15T12:35:18.439156Z","shell.execute_reply.started":"2024-03-15T12:35:17.515788Z","shell.execute_reply":"2024-03-15T12:35:18.438252Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Test Accuracy: 80.22%\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import precision_score, \\\n    recall_score, confusion_matrix, classification_report, \\\n    accuracy_score, f1_score\n\nprint ('\\n clasification report:\\n', classification_report(y_test, y_pred_test))\n\nprint('Матрица несоответствий для тестовой выборки:\\n')\nfig, ax = plt.subplots(figsize=(5, 5))\ndisp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test))\ndisp.plot(cmap = 'Blues', ax=ax);","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:35:18.441157Z","iopub.execute_input":"2024-03-15T12:35:18.441526Z","iopub.status.idle":"2024-03-15T12:35:18.753605Z","shell.execute_reply.started":"2024-03-15T12:35:18.441482Z","shell.execute_reply":"2024-03-15T12:35:18.752769Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"\n clasification report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.82      0.82        97\n           1       0.80      0.78      0.79        85\n\n    accuracy                           0.80       182\n   macro avg       0.80      0.80      0.80       182\nweighted avg       0.80      0.80      0.80       182\n\nМатрица несоответствий для тестовой выборки:\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'resnet18.pt')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:35:18.754821Z","iopub.execute_input":"2024-03-15T12:35:18.755081Z","iopub.status.idle":"2024-03-15T12:35:18.844910Z","shell.execute_reply.started":"2024-03-15T12:35:18.755058Z","shell.execute_reply":"2024-03-15T12:35:18.844139Z"},"trusted":true},"execution_count":38,"outputs":[]}]}