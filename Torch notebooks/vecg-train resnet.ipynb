{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7832335,"sourceType":"datasetVersion","datasetId":4533177}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-15T10:59:42.620383Z","iopub.execute_input":"2024-03-15T10:59:42.620722Z","iopub.status.idle":"2024-03-15T10:59:43.598076Z","shell.execute_reply.started":"2024-03-15T10:59:42.620695Z","shell.execute_reply":"2024-03-15T10:59:43.597188Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ecg-data/CWT.py\n/kaggle/input/ecg-data/check_preproc_df\n/kaggle/input/ecg-data/VECG.py\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install neurokit2","metadata":{"execution":{"iopub.status.busy":"2024-03-15T10:59:43.599695Z","iopub.execute_input":"2024-03-15T10:59:43.600073Z","iopub.status.idle":"2024-03-15T10:59:57.153721Z","shell.execute_reply.started":"2024-03-15T10:59:43.600047Z","shell.execute_reply":"2024-03-15T10:59:57.152619Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting neurokit2\n  Downloading neurokit2-0.2.7-py2.py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from neurokit2) (2.1.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.11.4)\nRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from neurokit2) (3.7.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (3.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\nDownloading neurokit2-0.2.7-py2.py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: neurokit2\nSuccessfully installed neurokit2-0.2.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import Subset\nfrom torch.utils.data import TensorDataset\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport sys\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-03-15T10:59:57.155350Z","iopub.execute_input":"2024-03-15T10:59:57.156145Z","iopub.status.idle":"2024-03-15T11:00:04.814295Z","shell.execute_reply.started":"2024-03-15T10:59:57.156105Z","shell.execute_reply":"2024-03-15T11:00:04.813502Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Подгружаем пути к директориям с нашими алгоритмами:\ncur_dir = os.getcwd()\nwavelets_path = os.path.join(cur_dir, \"../input/ecg-data/\")\nscript_path = os.path.join(cur_dir, \"../input/ecg-data/\")\nprint(script_path)\nprint(wavelets_path)\nsys.path.append(wavelets_path)\nsys.path.append(script_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:00:04.816274Z","iopub.execute_input":"2024-03-15T11:00:04.816706Z","iopub.status.idle":"2024-03-15T11:00:04.823628Z","shell.execute_reply.started":"2024-03-15T11:00:04.816679Z","shell.execute_reply":"2024-03-15T11:00:04.822255Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/../input/ecg-data/\n/kaggle/working/../input/ecg-data/\n","output_type":"stream"}]},{"cell_type":"code","source":"# Подгружаем алгоритмы для подготовки данных:\nimport VECG as vecg # Алгоритмы для формирования векторного представления кардиоциклов\nimport CWT as wt # Алгоритмы для вейвлет преобразования графиков ЭКГ","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:00:04.824899Z","iopub.execute_input":"2024-03-15T11:00:04.825264Z","iopub.status.idle":"2024-03-15T11:00:05.933820Z","shell.execute_reply.started":"2024-03-15T11:00:04.825234Z","shell.execute_reply":"2024-03-15T11:00:05.933024Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_size = 1000","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:00:05.935004Z","iopub.execute_input":"2024-03-15T11:00:05.935572Z","iopub.status.idle":"2024-03-15T11:00:05.939783Z","shell.execute_reply.started":"2024-03-15T11:00:05.935536Z","shell.execute_reply":"2024-03-15T11:00:05.938811Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ECG_df = pd.read_pickle('/kaggle/input/ecg-data/check_preproc_df')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:00:05.941211Z","iopub.execute_input":"2024-03-15T11:00:05.941498Z","iopub.status.idle":"2024-03-15T11:00:17.352357Z","shell.execute_reply.started":"2024-03-15T11:00:05.941474Z","shell.execute_reply":"2024-03-15T11:00:17.351511Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ECG_df = ECG_df[0:2*data_size]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:00:17.353392Z","iopub.execute_input":"2024-03-15T11:00:17.353654Z","iopub.status.idle":"2024-03-15T11:00:17.358023Z","shell.execute_reply.started":"2024-03-15T11:00:17.353632Z","shell.execute_reply":"2024-03-15T11:00:17.357123Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"vecg.init(filtering=True, canc_showing=True, plot3D=False, enable_centering = True, enable_local_normalize=True)\nECG_df = vecg.make_vecg_df(ECG_df, 0, 2)\nECG_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:00:17.359152Z","iopub.execute_input":"2024-03-15T11:00:17.359421Z","iopub.status.idle":"2024-03-15T11:09:02.458789Z","shell.execute_reply.started":"2024-03-15T11:00:17.359397Z","shell.execute_reply":"2024-03-15T11:09:02.457897Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Я в процессе\nЯ кончил\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   data label  \\\n855   [[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.024, 0...    AF   \n1523  [[-0.015, -0.015, -0.015, -0.015, -0.015, -0.0...    SR   \n80    [[0.095, 0.095, 0.095, 0.095, 0.095, 0.095, 0....    AF   \n593   [[-0.195, -0.195, -0.195, -0.195, -0.195, -0.1...    AF   \n1145  [[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0...    SR   \n\n                                                     XY  \\\n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n\n                                                     YZ  \\\n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n\n                                                     ZX  \n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>label</th>\n      <th>XY</th>\n      <th>YZ</th>\n      <th>ZX</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>855</th>\n      <td>[[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.024, 0...</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1523</th>\n      <td>[[-0.015, -0.015, -0.015, -0.015, -0.015, -0.0...</td>\n      <td>SR</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>[[0.095, 0.095, 0.095, 0.095, 0.095, 0.095, 0....</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>[[-0.195, -0.195, -0.195, -0.195, -0.195, -0.1...</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1145</th>\n      <td>[[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0...</td>\n      <td>SR</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def binarize(X):\n    for i, row in X.iterrows():\n        X.at[i, \"XY\"][X.at[i, \"XY\"] == 255] = 0\n        X.at[i, \"XY\"][X.at[i, \"XY\"] != 0] = 1\n        \n        X.at[i, \"YZ\"][X.at[i, \"YZ\"] == 255] = 0\n        X.at[i, \"YZ\"][X.at[i, \"YZ\"] != 0] = 1\n        \n        X.at[i, \"ZX\"][X.at[i, \"ZX\"] == 255] = 0\n        X.at[i, \"ZX\"][X.at[i, \"ZX\"] != 0] = 1\n            ","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:02.462686Z","iopub.execute_input":"2024-03-15T11:09:02.463033Z","iopub.status.idle":"2024-03-15T11:09:02.470049Z","shell.execute_reply.started":"2024-03-15T11:09:02.463003Z","shell.execute_reply":"2024-03-15T11:09:02.469069Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import gc\ndef transform(X):\n    #for i in range(X.shape[1]):\n    X[0][:] = X[0][:] - 0.485\n    X[1][:] = X[1][:] - 0.456\n    X[2][:] = X[2][:] - 0.406\n        \n    X[0][:] = X[0][:] / 0.229\n    X[1][:] = X[1][:] / 0.224\n    X[2][:] = X[2][:] / 0.225\n    gc.collect()\n    return X","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:02.471077Z","iopub.execute_input":"2024-03-15T11:09:02.471371Z","iopub.status.idle":"2024-03-15T11:09:02.481718Z","shell.execute_reply.started":"2024-03-15T11:09:02.471345Z","shell.execute_reply":"2024-03-15T11:09:02.480816Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"binarize(ECG_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:02.482896Z","iopub.execute_input":"2024-03-15T11:09:02.483143Z","iopub.status.idle":"2024-03-15T11:09:09.487015Z","shell.execute_reply.started":"2024-03-15T11:09:02.483122Z","shell.execute_reply":"2024-03-15T11:09:09.485705Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#transform(ECG_df)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:09.488611Z","iopub.execute_input":"2024-03-15T11:09:09.488957Z","iopub.status.idle":"2024-03-15T11:09:19.814702Z","shell.execute_reply.started":"2024-03-15T11:09:09.488929Z","shell.execute_reply":"2024-03-15T11:09:19.813732Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"12732000"},"metadata":{}}]},{"cell_type":"code","source":"# Формируем непосредственно набор данных и меток:\nX_ECG = np.array([ECG_df.iloc[:,2].tolist(),\n                 ECG_df.iloc[:,3].tolist(),\n                 ECG_df.iloc[:,4].tolist()])\nX_ECG = X_ECG.astype(\"float32\")\nX_ECG = transform(X_ECG)\nX_ECG = np.transpose(X_ECG, (1, 2, 3, 0))\n#X_ECG[X_ECG == 255 ] = 0\n#X_ECG[X_ECG != 0] = 1\ny_ECG = np.array(ECG_df.iloc[:,1].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:19.815870Z","iopub.execute_input":"2024-03-15T11:09:19.816180Z","iopub.status.idle":"2024-03-15T11:09:35.247776Z","shell.execute_reply.started":"2024-03-15T11:09:19.816155Z","shell.execute_reply":"2024-03-15T11:09:35.246823Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Производим деление выборки на тренировочную и тестовую\nX_train, X_test = (X_ECG[:int(data_size *10/11)*2], X_ECG[int(data_size *10/11)*2:data_size*2])\ny_train, y_test = (y_ECG[:int(data_size *10/11)*2], y_ECG[int(data_size *10/11)*2:data_size*2])\n\nX_ECG = 0\ny_ECG = 0\ngc.collect()\n\nX_val, y_val = X_train[:int(data_size * 1/10) * 2], y_train[:int(data_size * 1/10) * 2]\nX_train, y_train = X_train[int(data_size * 1/10) * 2:], y_train[int(data_size * 1/10) * 2:]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.249281Z","iopub.execute_input":"2024-03-15T11:09:35.249634Z","iopub.status.idle":"2024-03-15T11:09:35.414584Z","shell.execute_reply.started":"2024-03-15T11:09:35.249604Z","shell.execute_reply":"2024-03-15T11:09:35.413544Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train = np.transpose(X_train, (0, 3, 1, 2 ))\nX_test = np.transpose(X_test, (0, 3, 1, 2))\nX_val = np.transpose(X_val, (0, 3, 1, 2))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.415779Z","iopub.execute_input":"2024-03-15T11:09:35.416092Z","iopub.status.idle":"2024-03-15T11:09:35.426872Z","shell.execute_reply.started":"2024-03-15T11:09:35.416067Z","shell.execute_reply":"2024-03-15T11:09:35.426043Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Нормируем данные\n# X_train = X_train.astype('float32')\n# X_test = X_test.astype('float32')\n# X_val = X_val.astype('float32')\n# X_train = X_train / 255.0 * 0.99 + 0.01\n# X_test = X_test / 255.0 * 0.99 + 0.01","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.428287Z","iopub.execute_input":"2024-03-15T11:09:35.428571Z","iopub.status.idle":"2024-03-15T11:09:35.440102Z","shell.execute_reply.started":"2024-03-15T11:09:35.428548Z","shell.execute_reply":"2024-03-15T11:09:35.439227Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y_train = np.array([1 if label == \"SR\" else 0 for label in y_train])\ny_test = np.array([1 if label == \"SR\" else 0 for label in y_test])\ny_val = np.array([1 if label == \"SR\" else 0 for label in y_val])","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.441381Z","iopub.execute_input":"2024-03-15T11:09:35.442124Z","iopub.status.idle":"2024-03-15T11:09:35.451497Z","shell.execute_reply.started":"2024-03-15T11:09:35.442092Z","shell.execute_reply":"2024-03-15T11:09:35.450640Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# # Производим энкодинг полученных меток классов в удобный для обработки сетью вид\n# print('Метка класса перед энкодингом:', y_train[:10])\n# encoder = OneHotEncoder()\n# encoder.fit(y_train.reshape(-1, 1))\n# y_train = encoder.transform(y_train.reshape(-1, 1)).toarray()\n# y_test = encoder.transform(y_test.reshape(-1, 1)).toarray()\n# y_val = encoder.transform(y_val.reshape(-1, 1)).toarray()\n# print('Метка класса после энкодинга:', y_train[:10])\n# encoder.categories_","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.452500Z","iopub.execute_input":"2024-03-15T11:09:35.452763Z","iopub.status.idle":"2024-03-15T11:09:35.461413Z","shell.execute_reply.started":"2024-03-15T11:09:35.452740Z","shell.execute_reply":"2024-03-15T11:09:35.460644Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.462449Z","iopub.execute_input":"2024-03-15T11:09:35.462717Z","iopub.status.idle":"2024-03-15T11:09:35.471277Z","shell.execute_reply.started":"2024-03-15T11:09:35.462688Z","shell.execute_reply":"2024-03-15T11:09:35.470491Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(1618,)\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.472335Z","iopub.execute_input":"2024-03-15T11:09:35.472638Z","iopub.status.idle":"2024-03-15T11:09:35.636077Z","shell.execute_reply.started":"2024-03-15T11:09:35.472615Z","shell.execute_reply":"2024-03-15T11:09:35.635135Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# Создание Dataset и DataLoader\ntrain_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ntest_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\nval_dataset = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.637347Z","iopub.execute_input":"2024-03-15T11:09:35.638001Z","iopub.status.idle":"2024-03-15T11:09:35.655500Z","shell.execute_reply.started":"2024-03-15T11:09:35.637964Z","shell.execute_reply":"2024-03-15T11:09:35.654643Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X_train = 0\nX_test = 0\nX_val = 0\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.656769Z","iopub.execute_input":"2024-03-15T11:09:35.657114Z","iopub.status.idle":"2024-03-15T11:09:35.811137Z","shell.execute_reply.started":"2024-03-15T11:09:35.657084Z","shell.execute_reply":"2024-03-15T11:09:35.810085Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 15\n\ntrain_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True)\nval_dataloader = DataLoader(val_dataset, batch_size, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.812317Z","iopub.execute_input":"2024-03-15T11:09:35.812628Z","iopub.status.idle":"2024-03-15T11:09:35.820629Z","shell.execute_reply.started":"2024-03-15T11:09:35.812602Z","shell.execute_reply":"2024-03-15T11:09:35.819794Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#googlenet = torchvision.models.googlenet(pretrained=True)\nresnet18 = torchvision.models.resnet18(pretrained=True)\nmodel = resnet18","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:35.821633Z","iopub.execute_input":"2024-03-15T11:09:35.821910Z","iopub.status.idle":"2024-03-15T11:09:36.544478Z","shell.execute_reply.started":"2024-03-15T11:09:35.821883Z","shell.execute_reply":"2024-03-15T11:09:36.543522Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 149MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:36.545830Z","iopub.execute_input":"2024-03-15T11:09:36.546203Z","iopub.status.idle":"2024-03-15T11:09:36.813025Z","shell.execute_reply.started":"2024-03-15T11:09:36.546170Z","shell.execute_reply":"2024-03-15T11:09:36.812113Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:36.814234Z","iopub.execute_input":"2024-03-15T11:09:36.814549Z","iopub.status.idle":"2024-03-15T11:09:36.984073Z","shell.execute_reply.started":"2024-03-15T11:09:36.814523Z","shell.execute_reply":"2024-03-15T11:09:36.982960Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch\nimport torch.nn as nn\n\nclass InceptionBlock(nn.Module):\n    def __init__(self, in_channels, out1x1, red3x3, out3x3, red5x5, out5x5, out1x1pool):\n        super(InceptionBlock, self).__init__()\n        # 1x1 convolution\n        self.branch1x1 = nn.Conv2d(in_channels, out1x1, kernel_size=1)\n\n        # 1x1 convolution followed by 3x3 convolution\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, red3x3, kernel_size=1),\n            nn.Conv2d(red3x3, out3x3, kernel_size=3, padding=1)\n        )\n\n        # 1x1 convolution followed by 5x5 convolution\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, red5x5, kernel_size=1),\n            nn.Conv2d(red5x5, out5x5, kernel_size=5, padding=2)\n        )\n\n        # 3x3 max pooling followed by 1x1 convolution\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, out1x1pool, kernel_size=1)\n        )\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n\n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass GoogLeNet(nn.Module):\n    def __init__(self, num_classes=2):\n        super(GoogLeNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Inception blocks\n        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n\n        # Global average pooling\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n        # Fully connected layer\n        self.fc = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = self.maxpool2(F.relu(self.conv2(x)))\n        x = self.maxpool3(self.inception3a(x))\n        x = self.maxpool4(self.inception4e(self.inception4d(self.inception4c(self.inception4b(self.inception4a(x))))))\n        x = self.inception5b(self.inception5a(x))\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:36.988829Z","iopub.execute_input":"2024-03-15T11:09:36.989547Z","iopub.status.idle":"2024-03-15T11:09:37.009600Z","shell.execute_reply.started":"2024-03-15T11:09:36.989519Z","shell.execute_reply":"2024-03-15T11:09:37.008642Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\n\nclass FocalLoss(nn.Module):\n    \"Focal loss implemented using F.cross_entropy\"\n    def __init__(self, gamma: float = 2.0, weight=None, reduction: str = 'mean') -> None:\n        super().__init__()\n        self.gamma = gamma\n        self.weight = weight\n        self.reduction = reduction\n\n\n    def forward(self, inp: torch.Tensor, targ: torch.Tensor):\n        ce_loss = F.cross_entropy(inp, targ, weight=self.weight, reduction=\"none\")\n        p_t = torch.exp(-ce_loss)\n        loss = (1 - p_t)**self.gamma * ce_loss\n        if self.reduction == \"mean\":\n            loss = loss.mean()\n        elif self.reduction == \"sum\":\n            loss = loss.sum()\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:37.010711Z","iopub.execute_input":"2024-03-15T11:09:37.011033Z","iopub.status.idle":"2024-03-15T11:09:37.023168Z","shell.execute_reply.started":"2024-03-15T11:09:37.011008Z","shell.execute_reply":"2024-03-15T11:09:37.022383Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#googlenet = GoogLeNet(num_classes = 2)\n#Changing the last fc to 4 output features\n#GoogLeNet.fc = torch.nn.Linear(in_features=512, out_features=4)\n# Заменяем последний fully connected слой для задачи классификации\nnum_classes = 2  # Замените на количество классов в вашей задаче\nmodel.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n\ncriterion = torch.nn.CrossEntropyLoss()\n#criterion = FocalLoss()\n\n#optimizer = torch.optim.ASGD(googlenet.parameters(), lr=3e-4)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n#optimizer = optim.LBFGS(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:37.024206Z","iopub.execute_input":"2024-03-15T11:09:37.024487Z","iopub.status.idle":"2024-03-15T11:09:37.033251Z","shell.execute_reply.started":"2024-03-15T11:09:37.024458Z","shell.execute_reply":"2024-03-15T11:09:37.032535Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, criterion, device):\n    model.eval()  # Переводим модель в режим оценки (без обновления весов)\n\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for val_step, (images, labels) in enumerate(dataloader):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / total\n    print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n\n    model.train()  # Возвращаем модель в режим обучения","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:37.034255Z","iopub.execute_input":"2024-03-15T11:09:37.034580Z","iopub.status.idle":"2024-03-15T11:09:37.045049Z","shell.execute_reply.started":"2024-03-15T11:09:37.034547Z","shell.execute_reply":"2024-03-15T11:09:37.044252Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs):\n    print('Starting training..')\n    for e in range(0, epochs):\n        print('='*20)\n        print(f'Starting epoch {e + 1}/{epochs}')\n        print('='*20)\n\n        train_loss = 0.\n        val_loss = 0.  # Not computing val_loss since we'll be evaluating the model multiple times within one epoch\n        \n        model.train() # set model to training phase\n        model.to(device)\n        \n        for train_step, (images, labels) in enumerate(train_dataloader):\n            optimizer.zero_grad()\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            # Once we get the loss we need to take a gradient step\n            loss.backward() # Back propagation\n            optimizer.step() # Completes the gradient step by updating all the parameter values (we are using all parameters)\n            train_loss += loss.item() # Loss is a tensor which can't be added to train_loss so .item() converts it to float\n               \n\n        train_loss /= (train_step + 1)\n\n        print(f'Training Loss: {train_loss:.4f}')\n        validate(model, val_dataloader, criterion, device)\n    print('Training complete..')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:37.046218Z","iopub.execute_input":"2024-03-15T11:09:37.046486Z","iopub.status.idle":"2024-03-15T11:09:37.057391Z","shell.execute_reply.started":"2024-03-15T11:09:37.046462Z","shell.execute_reply":"2024-03-15T11:09:37.056588Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntrain(model=model, epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:09:37.058349Z","iopub.execute_input":"2024-03-15T11:09:37.058599Z","iopub.status.idle":"2024-03-15T11:25:03.169862Z","shell.execute_reply.started":"2024-03-15T11:09:37.058576Z","shell.execute_reply":"2024-03-15T11:25:03.168598Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Starting training..\n====================\nStarting epoch 1/50\n====================\nTraining Loss: 0.6290\nValidation Accuracy: 69.00%\n====================\nStarting epoch 2/50\n====================\nTraining Loss: 0.4687\nValidation Accuracy: 69.00%\n====================\nStarting epoch 3/50\n====================\nTraining Loss: 0.4013\nValidation Accuracy: 67.00%\n====================\nStarting epoch 4/50\n====================\nTraining Loss: 0.3717\nValidation Accuracy: 73.00%\n====================\nStarting epoch 5/50\n====================\nTraining Loss: 0.3075\nValidation Accuracy: 76.00%\n====================\nStarting epoch 6/50\n====================\nTraining Loss: 0.2486\nValidation Accuracy: 65.00%\n====================\nStarting epoch 7/50\n====================\nTraining Loss: 0.2341\nValidation Accuracy: 73.00%\n====================\nStarting epoch 8/50\n====================\nTraining Loss: 0.1557\nValidation Accuracy: 70.00%\n====================\nStarting epoch 9/50\n====================\nTraining Loss: 0.1467\nValidation Accuracy: 62.50%\n====================\nStarting epoch 10/50\n====================\nTraining Loss: 0.1300\nValidation Accuracy: 76.00%\n====================\nStarting epoch 11/50\n====================\nTraining Loss: 0.1189\nValidation Accuracy: 78.00%\n====================\nStarting epoch 12/50\n====================\nTraining Loss: 0.0867\nValidation Accuracy: 74.50%\n====================\nStarting epoch 13/50\n====================\nTraining Loss: 0.0803\nValidation Accuracy: 76.00%\n====================\nStarting epoch 14/50\n====================\nTraining Loss: 0.0436\nValidation Accuracy: 74.50%\n====================\nStarting epoch 15/50\n====================\nTraining Loss: 0.0402\nValidation Accuracy: 78.50%\n====================\nStarting epoch 16/50\n====================\nTraining Loss: 0.0465\nValidation Accuracy: 73.00%\n====================\nStarting epoch 17/50\n====================\nTraining Loss: 0.0358\nValidation Accuracy: 76.00%\n====================\nStarting epoch 18/50\n====================\nTraining Loss: 0.0222\nValidation Accuracy: 77.50%\n====================\nStarting epoch 19/50\n====================\nTraining Loss: 0.0715\nValidation Accuracy: 72.00%\n====================\nStarting epoch 20/50\n====================\nTraining Loss: 0.0566\nValidation Accuracy: 79.00%\n====================\nStarting epoch 21/50\n====================\nTraining Loss: 0.0183\nValidation Accuracy: 77.50%\n====================\nStarting epoch 22/50\n====================\nTraining Loss: 0.0099\nValidation Accuracy: 76.50%\n====================\nStarting epoch 23/50\n====================\nTraining Loss: 0.0361\nValidation Accuracy: 76.00%\n====================\nStarting epoch 24/50\n====================\nTraining Loss: 0.0287\nValidation Accuracy: 76.00%\n====================\nStarting epoch 25/50\n====================\nTraining Loss: 0.0302\nValidation Accuracy: 78.50%\n====================\nStarting epoch 26/50\n====================\nTraining Loss: 0.0674\nValidation Accuracy: 76.50%\n====================\nStarting epoch 27/50\n====================\nTraining Loss: 0.0488\nValidation Accuracy: 77.50%\n====================\nStarting epoch 28/50\n====================\nTraining Loss: 0.0365\nValidation Accuracy: 76.00%\n====================\nStarting epoch 29/50\n====================\nTraining Loss: 0.0163\nValidation Accuracy: 79.00%\n====================\nStarting epoch 30/50\n====================\nTraining Loss: 0.0047\nValidation Accuracy: 78.00%\n====================\nStarting epoch 31/50\n====================\nTraining Loss: 0.0021\nValidation Accuracy: 79.50%\n====================\nStarting epoch 32/50\n====================\nTraining Loss: 0.0009\nValidation Accuracy: 79.00%\n====================\nStarting epoch 33/50\n====================\nTraining Loss: 0.0004\nValidation Accuracy: 79.50%\n====================\nStarting epoch 34/50\n====================\nTraining Loss: 0.0003\nValidation Accuracy: 79.50%\n====================\nStarting epoch 35/50\n====================\nTraining Loss: 0.0002\nValidation Accuracy: 80.00%\n====================\nStarting epoch 36/50\n====================\nTraining Loss: 0.0002\nValidation Accuracy: 80.50%\n====================\nStarting epoch 37/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 80.00%\n====================\nStarting epoch 38/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 79.50%\n====================\nStarting epoch 39/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 79.00%\n====================\nStarting epoch 40/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 79.00%\n====================\nStarting epoch 41/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 79.00%\n====================\nStarting epoch 42/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 79.00%\n====================\nStarting epoch 43/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 79.00%\n====================\nStarting epoch 44/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 79.00%\n====================\nStarting epoch 45/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 79.00%\n====================\nStarting epoch 46/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 79.00%\n====================\nStarting epoch 47/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 79.00%\n====================\nStarting epoch 48/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 79.00%\n====================\nStarting epoch 49/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 79.00%\n====================\nStarting epoch 50/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 79.00%\nTraining complete..\nCPU times: user 15min 59s, sys: 2min 50s, total: 18min 49s\nWall time: 15min 26s\n","output_type":"stream"}]},{"cell_type":"code","source":"def test(model, dataloader, criterion, device):\n    model.eval()  # Переводим модель в режим оценки (без обновления весов)\n\n    correct = 0\n    total = 0\n    y_pred = []\n\n    with torch.no_grad():\n        for val_step, (images, labels) in enumerate(dataloader):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            y_pred.extend(predicted.cpu().numpy())\n    accuracy = correct / total\n    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n\n    model.train()  # Возвращаем модель в режим обучения\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:25:03.171264Z","iopub.execute_input":"2024-03-15T11:25:03.171724Z","iopub.status.idle":"2024-03-15T11:25:03.180315Z","shell.execute_reply.started":"2024-03-15T11:25:03.171688Z","shell.execute_reply":"2024-03-15T11:25:03.179331Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"y_pred_test = test(model, test_dataloader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:25:03.181616Z","iopub.execute_input":"2024-03-15T11:25:03.182041Z","iopub.status.idle":"2024-03-15T11:25:04.074001Z","shell.execute_reply.started":"2024-03-15T11:25:03.182008Z","shell.execute_reply":"2024-03-15T11:25:04.073093Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Test Accuracy: 79.12%\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import precision_score, \\\n    recall_score, confusion_matrix, classification_report, \\\n    accuracy_score, f1_score\n\nprint ('\\n clasification report:\\n', classification_report(y_test, y_pred_test))\n\nprint('Матрица несоответствий для тестовой выборки:\\n')\nfig, ax = plt.subplots(figsize=(5, 5))\ndisp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test))\ndisp.plot(cmap = 'Blues', ax=ax);","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:25:04.075327Z","iopub.execute_input":"2024-03-15T11:25:04.075763Z","iopub.status.idle":"2024-03-15T11:25:04.385767Z","shell.execute_reply.started":"2024-03-15T11:25:04.075729Z","shell.execute_reply":"2024-03-15T11:25:04.384835Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"\n clasification report:\n               precision    recall  f1-score   support\n\n           0       0.76      0.89      0.82        97\n           1       0.84      0.68      0.75        85\n\n    accuracy                           0.79       182\n   macro avg       0.80      0.78      0.79       182\nweighted avg       0.80      0.79      0.79       182\n\nМатрица несоответствий для тестовой выборки:\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'resnet18.pt')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T11:33:33.468131Z","iopub.execute_input":"2024-03-15T11:33:33.469071Z","iopub.status.idle":"2024-03-15T11:33:33.548996Z","shell.execute_reply.started":"2024-03-15T11:33:33.469033Z","shell.execute_reply":"2024-03-15T11:33:33.548176Z"},"trusted":true},"execution_count":38,"outputs":[]}]}