{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7832335,"sourceType":"datasetVersion","datasetId":4533177}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-13T17:10:38.340844Z","iopub.execute_input":"2024-03-13T17:10:38.341668Z","iopub.status.idle":"2024-03-13T17:10:39.294166Z","shell.execute_reply.started":"2024-03-13T17:10:38.341634Z","shell.execute_reply":"2024-03-13T17:10:39.293233Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ecg-data/CWT.py\n/kaggle/input/ecg-data/check_preproc_df\n/kaggle/input/ecg-data/VECG.py\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install neurokit2","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:10:39.296168Z","iopub.execute_input":"2024-03-13T17:10:39.296873Z","iopub.status.idle":"2024-03-13T17:10:53.492422Z","shell.execute_reply.started":"2024-03-13T17:10:39.296844Z","shell.execute_reply":"2024-03-13T17:10:53.491223Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting neurokit2\n  Downloading neurokit2-0.2.7-py2.py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from neurokit2) (2.1.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.11.4)\nRequirement already satisfied: scikit-learn>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from neurokit2) (1.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from neurokit2) (3.7.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.0->neurokit2) (3.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->neurokit2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neurokit2) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->neurokit2) (1.16.0)\nDownloading neurokit2-0.2.7-py2.py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: neurokit2\nSuccessfully installed neurokit2-0.2.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import Subset\nfrom torch.utils.data import TensorDataset\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport matplotlib.pyplot as plt\nimport sys\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:10:53.493768Z","iopub.execute_input":"2024-03-13T17:10:53.494082Z","iopub.status.idle":"2024-03-13T17:11:00.328033Z","shell.execute_reply.started":"2024-03-13T17:10:53.494052Z","shell.execute_reply":"2024-03-13T17:11:00.327260Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Подгружаем пути к директориям с нашими алгоритмами:\ncur_dir = os.getcwd()\nwavelets_path = os.path.join(cur_dir, \"../input/ecg-data/\")\nscript_path = os.path.join(cur_dir, \"../input/ecg-data/\")\nprint(script_path)\nprint(wavelets_path)\nsys.path.append(wavelets_path)\nsys.path.append(script_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:11:00.330177Z","iopub.execute_input":"2024-03-13T17:11:00.330599Z","iopub.status.idle":"2024-03-13T17:11:00.336309Z","shell.execute_reply.started":"2024-03-13T17:11:00.330571Z","shell.execute_reply":"2024-03-13T17:11:00.335449Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/../input/ecg-data/\n/kaggle/working/../input/ecg-data/\n","output_type":"stream"}]},{"cell_type":"code","source":"# Подгружаем алгоритмы для подготовки данных:\nimport VECG as vecg # Алгоритмы для формирования векторного представления кардиоциклов\nimport CWT as wt # Алгоритмы для вейвлет преобразования графиков ЭКГ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:11:00.337462Z","iopub.execute_input":"2024-03-13T17:11:00.337808Z","iopub.status.idle":"2024-03-13T17:11:01.479103Z","shell.execute_reply.started":"2024-03-13T17:11:00.337774Z","shell.execute_reply":"2024-03-13T17:11:01.478275Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_size = 1000","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:11:01.480293Z","iopub.execute_input":"2024-03-13T17:11:01.480860Z","iopub.status.idle":"2024-03-13T17:11:01.485515Z","shell.execute_reply.started":"2024-03-13T17:11:01.480824Z","shell.execute_reply":"2024-03-13T17:11:01.484622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ECG_df = pd.read_pickle('/kaggle/input/ecg-data/check_preproc_df')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:11:01.486876Z","iopub.execute_input":"2024-03-13T17:11:01.488633Z","iopub.status.idle":"2024-03-13T17:11:09.300811Z","shell.execute_reply.started":"2024-03-13T17:11:01.488599Z","shell.execute_reply":"2024-03-13T17:11:09.300018Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ECG_df = ECG_df[0:2*data_size]","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:11:09.301891Z","iopub.execute_input":"2024-03-13T17:11:09.302228Z","iopub.status.idle":"2024-03-13T17:11:09.306613Z","shell.execute_reply.started":"2024-03-13T17:11:09.302202Z","shell.execute_reply":"2024-03-13T17:11:09.305797Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"vecg.init(filtering=True, canc_showing=True, plot3D=False, enable_centering = True, enable_local_normalize=True)\nECG_df = vecg.make_vecg_df(ECG_df, 0, 2)\nECG_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:11:09.307679Z","iopub.execute_input":"2024-03-13T17:11:09.307950Z","iopub.status.idle":"2024-03-13T17:20:23.993804Z","shell.execute_reply.started":"2024-03-13T17:11:09.307926Z","shell.execute_reply":"2024-03-13T17:20:23.992823Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Я в процессе\nЯ кончил\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   data label  \\\n855   [[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.024, 0...    AF   \n1523  [[-0.015, -0.015, -0.015, -0.015, -0.015, -0.0...    SR   \n80    [[0.095, 0.095, 0.095, 0.095, 0.095, 0.095, 0....    AF   \n593   [[-0.195, -0.195, -0.195, -0.195, -0.195, -0.1...    AF   \n1145  [[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0...    SR   \n\n                                                     XY  \\\n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n\n                                                     YZ  \\\n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n\n                                                     ZX  \n855   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n1523  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n80    [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n593   [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  \n1145  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>label</th>\n      <th>XY</th>\n      <th>YZ</th>\n      <th>ZX</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>855</th>\n      <td>[[0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.024, 0...</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1523</th>\n      <td>[[-0.015, -0.015, -0.015, -0.015, -0.015, -0.0...</td>\n      <td>SR</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>[[0.095, 0.095, 0.095, 0.095, 0.095, 0.095, 0....</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>593</th>\n      <td>[[-0.195, -0.195, -0.195, -0.195, -0.195, -0.1...</td>\n      <td>AF</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n    <tr>\n      <th>1145</th>\n      <td>[[-0.04, -0.04, -0.04, -0.04, -0.04, -0.04, -0...</td>\n      <td>SR</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def binarize(X):\n    for i, row in X.iterrows():\n        X.at[i, \"XY\"][X.at[i, \"XY\"] == 255] = 0\n        X.at[i, \"XY\"][X.at[i, \"XY\"] != 0] = 1\n        \n        X.at[i, \"YZ\"][X.at[i, \"YZ\"] == 255] = 0\n        X.at[i, \"YZ\"][X.at[i, \"YZ\"] != 0] = 1\n        \n        X.at[i, \"ZX\"][X.at[i, \"ZX\"] == 255] = 0\n        X.at[i, \"ZX\"][X.at[i, \"ZX\"] != 0] = 1\n            ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:23.998992Z","iopub.execute_input":"2024-03-13T17:20:23.999288Z","iopub.status.idle":"2024-03-13T17:20:24.006254Z","shell.execute_reply.started":"2024-03-13T17:20:23.999261Z","shell.execute_reply":"2024-03-13T17:20:24.005368Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import gc\ndef transform(X):\n    #for i in range(X.shape[1]):\n    X[0][:] = X[0][:] - 0.485\n    X[1][:] = X[1][:] - 0.456\n    X[2][:] = X[2][:] - 0.406\n        \n    X[0][:] = X[0][:] / 0.229\n    X[1][:] = X[1][:] / 0.224\n    X[2][:] = X[2][:] / 0.225\n    gc.collect()\n    return X","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:24.007339Z","iopub.execute_input":"2024-03-13T17:20:24.007600Z","iopub.status.idle":"2024-03-13T17:20:24.018856Z","shell.execute_reply.started":"2024-03-13T17:20:24.007576Z","shell.execute_reply":"2024-03-13T17:20:24.018083Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"binarize(ECG_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:24.020336Z","iopub.execute_input":"2024-03-13T17:20:24.020926Z","iopub.status.idle":"2024-03-13T17:20:31.094386Z","shell.execute_reply.started":"2024-03-13T17:20:24.020894Z","shell.execute_reply":"2024-03-13T17:20:31.093214Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#transform(ECG_df)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:31.096081Z","iopub.execute_input":"2024-03-13T17:20:31.096456Z","iopub.status.idle":"2024-03-13T17:20:41.489244Z","shell.execute_reply.started":"2024-03-13T17:20:31.096419Z","shell.execute_reply":"2024-03-13T17:20:41.488388Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"12732000"},"metadata":{}}]},{"cell_type":"code","source":"# Формируем непосредственно набор данных и меток:\nX_ECG = np.array([ECG_df.iloc[:,2].tolist(),\n                 ECG_df.iloc[:,3].tolist(),\n                 ECG_df.iloc[:,4].tolist()])\nX_ECG = X_ECG.astype(\"float32\")\nX_ECG = transform(X_ECG)\nX_ECG = np.transpose(X_ECG, (1, 2, 3, 0))\n#X_ECG[X_ECG == 255 ] = 0\n#X_ECG[X_ECG != 0] = 1\ny_ECG = np.array(ECG_df.iloc[:,1].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:41.502313Z","iopub.execute_input":"2024-03-13T17:20:41.502593Z","iopub.status.idle":"2024-03-13T17:20:56.810010Z","shell.execute_reply.started":"2024-03-13T17:20:41.502569Z","shell.execute_reply":"2024-03-13T17:20:56.809259Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Производим деление выборки на тренировочную и тестовую\nX_train, X_test = (X_ECG[:int(data_size *10/11)*2], X_ECG[int(data_size *10/11)*2:data_size*2])\ny_train, y_test = (y_ECG[:int(data_size *10/11)*2], y_ECG[int(data_size *10/11)*2:data_size*2])\n\nX_ECG = 0\ny_ECG = 0\ngc.collect()\n\nX_val, y_val = X_train[:int(data_size * 1/10) * 2], y_train[:int(data_size * 1/10) * 2]\nX_train, y_train = X_train[int(data_size * 1/10) * 2:], y_train[int(data_size * 1/10) * 2:]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:56.811236Z","iopub.execute_input":"2024-03-13T17:20:56.811535Z","iopub.status.idle":"2024-03-13T17:20:56.967324Z","shell.execute_reply.started":"2024-03-13T17:20:56.811508Z","shell.execute_reply":"2024-03-13T17:20:56.966167Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train = np.transpose(X_train, (0, 3, 1, 2 ))\nX_test = np.transpose(X_test, (0, 3, 1, 2))\nX_val = np.transpose(X_val, (0, 3, 1, 2))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:56.969107Z","iopub.execute_input":"2024-03-13T17:20:56.969839Z","iopub.status.idle":"2024-03-13T17:20:56.979573Z","shell.execute_reply.started":"2024-03-13T17:20:56.969802Z","shell.execute_reply":"2024-03-13T17:20:56.978736Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Нормируем данные\n# X_train = X_train.astype('float32')\n# X_test = X_test.astype('float32')\n# X_val = X_val.astype('float32')\n# X_train = X_train / 255.0 * 0.99 + 0.01\n# X_test = X_test / 255.0 * 0.99 + 0.01","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:56.980617Z","iopub.execute_input":"2024-03-13T17:20:56.980937Z","iopub.status.idle":"2024-03-13T17:20:56.997124Z","shell.execute_reply.started":"2024-03-13T17:20:56.980905Z","shell.execute_reply":"2024-03-13T17:20:56.996075Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y_train = np.array([1 if label == \"SR\" else 0 for label in y_train])\ny_test = np.array([1 if label == \"SR\" else 0 for label in y_test])\ny_val = np.array([1 if label == \"SR\" else 0 for label in y_val])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:56.998368Z","iopub.execute_input":"2024-03-13T17:20:56.998935Z","iopub.status.idle":"2024-03-13T17:20:57.008772Z","shell.execute_reply.started":"2024-03-13T17:20:56.998904Z","shell.execute_reply":"2024-03-13T17:20:57.007992Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# # Производим энкодинг полученных меток классов в удобный для обработки сетью вид\n# print('Метка класса перед энкодингом:', y_train[:10])\n# encoder = OneHotEncoder()\n# encoder.fit(y_train.reshape(-1, 1))\n# y_train = encoder.transform(y_train.reshape(-1, 1)).toarray()\n# y_test = encoder.transform(y_test.reshape(-1, 1)).toarray()\n# y_val = encoder.transform(y_val.reshape(-1, 1)).toarray()\n# print('Метка класса после энкодинга:', y_train[:10])\n# encoder.categories_","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:57.009714Z","iopub.execute_input":"2024-03-13T17:20:57.010035Z","iopub.status.idle":"2024-03-13T17:20:57.018239Z","shell.execute_reply.started":"2024-03-13T17:20:57.010005Z","shell.execute_reply":"2024-03-13T17:20:57.017347Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:57.019225Z","iopub.execute_input":"2024-03-13T17:20:57.019450Z","iopub.status.idle":"2024-03-13T17:20:57.028452Z","shell.execute_reply.started":"2024-03-13T17:20:57.019430Z","shell.execute_reply":"2024-03-13T17:20:57.027581Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(1618,)\n","output_type":"stream"}]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:57.029450Z","iopub.execute_input":"2024-03-13T17:20:57.029727Z","iopub.status.idle":"2024-03-13T17:20:57.192675Z","shell.execute_reply.started":"2024-03-13T17:20:57.029704Z","shell.execute_reply":"2024-03-13T17:20:57.191655Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# Создание Dataset и DataLoader\ntrain_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\ntest_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\nval_dataset = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:57.193929Z","iopub.execute_input":"2024-03-13T17:20:57.194255Z","iopub.status.idle":"2024-03-13T17:20:57.211841Z","shell.execute_reply.started":"2024-03-13T17:20:57.194229Z","shell.execute_reply":"2024-03-13T17:20:57.211006Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"X_train = 0\nX_test = 0\nX_val = 0\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:57.213107Z","iopub.execute_input":"2024-03-13T17:20:57.213441Z","iopub.status.idle":"2024-03-13T17:20:57.368284Z","shell.execute_reply.started":"2024-03-13T17:20:57.213410Z","shell.execute_reply":"2024-03-13T17:20:57.367319Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 15\n\ntrain_dataloader = DataLoader(train_dataset, batch_size, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True)\nval_dataloader = DataLoader(val_dataset, batch_size, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:57.369610Z","iopub.execute_input":"2024-03-13T17:20:57.370238Z","iopub.status.idle":"2024-03-13T17:20:57.376897Z","shell.execute_reply.started":"2024-03-13T17:20:57.370204Z","shell.execute_reply":"2024-03-13T17:20:57.376160Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"googlenet = torchvision.models.googlenet(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:57.377966Z","iopub.execute_input":"2024-03-13T17:20:57.378252Z","iopub.status.idle":"2024-03-13T17:20:58.128617Z","shell.execute_reply.started":"2024-03-13T17:20:57.378229Z","shell.execute_reply":"2024-03-13T17:20:58.127778Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n100%|██████████| 49.7M/49.7M [00:00<00:00, 138MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ngooglenet.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.131205Z","iopub.execute_input":"2024-03-13T17:20:58.131653Z","iopub.status.idle":"2024-03-13T17:20:58.400113Z","shell.execute_reply.started":"2024-03-13T17:20:58.131619Z","shell.execute_reply":"2024-03-13T17:20:58.399134Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"GoogLeNet(\n  (conv1): BasicConv2d(\n    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (conv2): BasicConv2d(\n    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv3): BasicConv2d(\n    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception3a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception3b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception4a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4c): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4d): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4e): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception5a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception5b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (aux1): None\n  (aux2): None\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (dropout): Dropout(p=0.2, inplace=False)\n  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.401420Z","iopub.execute_input":"2024-03-13T17:20:58.401790Z","iopub.status.idle":"2024-03-13T17:20:58.589454Z","shell.execute_reply.started":"2024-03-13T17:20:58.401756Z","shell.execute_reply":"2024-03-13T17:20:58.588273Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport torch\nimport torch.nn as nn\n\nclass InceptionBlock(nn.Module):\n    def __init__(self, in_channels, out1x1, red3x3, out3x3, red5x5, out5x5, out1x1pool):\n        super(InceptionBlock, self).__init__()\n        # 1x1 convolution\n        self.branch1x1 = nn.Conv2d(in_channels, out1x1, kernel_size=1)\n\n        # 1x1 convolution followed by 3x3 convolution\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, red3x3, kernel_size=1),\n            nn.Conv2d(red3x3, out3x3, kernel_size=3, padding=1)\n        )\n\n        # 1x1 convolution followed by 5x5 convolution\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, red5x5, kernel_size=1),\n            nn.Conv2d(red5x5, out5x5, kernel_size=5, padding=2)\n        )\n\n        # 3x3 max pooling followed by 1x1 convolution\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, out1x1pool, kernel_size=1)\n        )\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n\n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\n\nclass GoogLeNet(nn.Module):\n    def __init__(self, num_classes=2):\n        super(GoogLeNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Inception blocks\n        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n\n        # Global average pooling\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n\n        # Fully connected layer\n        self.fc = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.maxpool1(F.relu(self.conv1(x)))\n        x = self.maxpool2(F.relu(self.conv2(x)))\n        x = self.maxpool3(self.inception3a(x))\n        x = self.maxpool4(self.inception4e(self.inception4d(self.inception4c(self.inception4b(self.inception4a(x))))))\n        x = self.inception5b(self.inception5a(x))\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.594472Z","iopub.execute_input":"2024-03-13T17:20:58.595028Z","iopub.status.idle":"2024-03-13T17:20:58.615090Z","shell.execute_reply.started":"2024-03-13T17:20:58.594985Z","shell.execute_reply":"2024-03-13T17:20:58.614087Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\n\nclass FocalLoss(nn.Module):\n    \"Focal loss implemented using F.cross_entropy\"\n    def __init__(self, gamma: float = 2.0, weight=None, reduction: str = 'mean') -> None:\n        super().__init__()\n        self.gamma = gamma\n        self.weight = weight\n        self.reduction = reduction\n\n\n    def forward(self, inp: torch.Tensor, targ: torch.Tensor):\n        ce_loss = F.cross_entropy(inp, targ, weight=self.weight, reduction=\"none\")\n        p_t = torch.exp(-ce_loss)\n        loss = (1 - p_t)**self.gamma * ce_loss\n        if self.reduction == \"mean\":\n            loss = loss.mean()\n        elif self.reduction == \"sum\":\n            loss = loss.sum()\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.616203Z","iopub.execute_input":"2024-03-13T17:20:58.616582Z","iopub.status.idle":"2024-03-13T17:20:58.629761Z","shell.execute_reply.started":"2024-03-13T17:20:58.616546Z","shell.execute_reply":"2024-03-13T17:20:58.628999Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#googlenet = GoogLeNet(num_classes = 2)\n#Changing the last fc to 4 output features\n#GoogLeNet.fc = torch.nn.Linear(in_features=512, out_features=4)\n# Заменяем последний fully connected слой для задачи классификации\nnum_classes = 2  # Замените на количество классов в вашей задаче\ngooglenet.fc = torch.nn.Linear(googlenet.fc.in_features, num_classes)\n\ncriterion = torch.nn.CrossEntropyLoss()\n#criterion = FocalLoss()\n\n#optimizer = torch.optim.ASGD(googlenet.parameters(), lr=3e-4)\noptimizer = torch.optim.AdamW(googlenet.parameters(), lr=0.001)\n#optimizer = optim.LBFGS(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.630764Z","iopub.execute_input":"2024-03-13T17:20:58.631076Z","iopub.status.idle":"2024-03-13T17:20:58.641381Z","shell.execute_reply.started":"2024-03-13T17:20:58.631051Z","shell.execute_reply":"2024-03-13T17:20:58.640627Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, criterion, device):\n    model.eval()  # Переводим модель в режим оценки (без обновления весов)\n\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for val_step, (images, labels) in enumerate(dataloader):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / total\n    print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n\n    model.train()  # Возвращаем модель в режим обучения","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.642473Z","iopub.execute_input":"2024-03-13T17:20:58.642803Z","iopub.status.idle":"2024-03-13T17:20:58.653358Z","shell.execute_reply.started":"2024-03-13T17:20:58.642772Z","shell.execute_reply":"2024-03-13T17:20:58.652480Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def train(model, epochs):\n    print('Starting training..')\n    for e in range(0, epochs):\n        print('='*20)\n        print(f'Starting epoch {e + 1}/{epochs}')\n        print('='*20)\n\n        train_loss = 0.\n        val_loss = 0.  # Not computing val_loss since we'll be evaluating the model multiple times within one epoch\n        \n        model.train() # set model to training phase\n        model.to(device)\n        \n        for train_step, (images, labels) in enumerate(train_dataloader):\n            optimizer.zero_grad()\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            # Once we get the loss we need to take a gradient step\n            loss.backward() # Back propagation\n            optimizer.step() # Completes the gradient step by updating all the parameter values (we are using all parameters)\n            train_loss += loss.item() # Loss is a tensor which can't be added to train_loss so .item() converts it to float\n               \n\n        train_loss /= (train_step + 1)\n\n        print(f'Training Loss: {train_loss:.4f}')\n        validate(model, val_dataloader, criterion, device)\n    print('Training complete..')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.654400Z","iopub.execute_input":"2024-03-13T17:20:58.654723Z","iopub.status.idle":"2024-03-13T17:20:58.664541Z","shell.execute_reply.started":"2024-03-13T17:20:58.654691Z","shell.execute_reply":"2024-03-13T17:20:58.663828Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntrain(model=googlenet, epochs=50)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T17:20:58.665458Z","iopub.execute_input":"2024-03-13T17:20:58.665694Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Starting training..\n====================\nStarting epoch 1/50\n====================\nTraining Loss: 0.5900\nValidation Accuracy: 74.50%\n====================\nStarting epoch 2/50\n====================\nTraining Loss: 0.4561\nValidation Accuracy: 73.00%\n====================\nStarting epoch 3/50\n====================\nTraining Loss: 0.3659\nValidation Accuracy: 60.50%\n====================\nStarting epoch 4/50\n====================\nTraining Loss: 0.3232\nValidation Accuracy: 74.00%\n====================\nStarting epoch 5/50\n====================\nTraining Loss: 0.2663\nValidation Accuracy: 72.00%\n====================\nStarting epoch 6/50\n====================\nTraining Loss: 0.1967\nValidation Accuracy: 68.00%\n====================\nStarting epoch 7/50\n====================\nTraining Loss: 0.1865\nValidation Accuracy: 75.00%\n====================\nStarting epoch 8/50\n====================\nTraining Loss: 0.1689\nValidation Accuracy: 67.00%\n====================\nStarting epoch 9/50\n====================\nTraining Loss: 0.1087\nValidation Accuracy: 70.00%\n====================\nStarting epoch 10/50\n====================\nTraining Loss: 0.1011\nValidation Accuracy: 52.50%\n====================\nStarting epoch 11/50\n====================\nTraining Loss: 0.0854\nValidation Accuracy: 71.50%\n====================\nStarting epoch 12/50\n====================\nTraining Loss: 0.0651\nValidation Accuracy: 74.50%\n====================\nStarting epoch 13/50\n====================\nTraining Loss: 0.1071\nValidation Accuracy: 74.00%\n====================\nStarting epoch 14/50\n====================\nTraining Loss: 0.0604\nValidation Accuracy: 72.00%\n====================\nStarting epoch 15/50\n====================\nTraining Loss: 0.0761\nValidation Accuracy: 74.50%\n====================\nStarting epoch 16/50\n====================\nTraining Loss: 0.0416\nValidation Accuracy: 69.50%\n====================\nStarting epoch 17/50\n====================\nTraining Loss: 0.0311\nValidation Accuracy: 66.00%\n====================\nStarting epoch 18/50\n====================\nTraining Loss: 0.0526\nValidation Accuracy: 66.50%\n====================\nStarting epoch 19/50\n====================\nTraining Loss: 0.0497\nValidation Accuracy: 74.00%\n====================\nStarting epoch 20/50\n====================\nTraining Loss: 0.0335\nValidation Accuracy: 74.00%\n====================\nStarting epoch 21/50\n====================\nTraining Loss: 0.0525\nValidation Accuracy: 73.00%\n====================\nStarting epoch 22/50\n====================\nTraining Loss: 0.0722\nValidation Accuracy: 73.00%\n====================\nStarting epoch 23/50\n====================\nTraining Loss: 0.0415\nValidation Accuracy: 72.50%\n====================\nStarting epoch 24/50\n====================\nTraining Loss: 0.0223\nValidation Accuracy: 71.00%\n====================\nStarting epoch 25/50\n====================\nTraining Loss: 0.0159\nValidation Accuracy: 76.50%\n====================\nStarting epoch 26/50\n====================\nTraining Loss: 0.0096\nValidation Accuracy: 75.00%\n====================\nStarting epoch 27/50\n====================\nTraining Loss: 0.0052\nValidation Accuracy: 76.00%\n====================\nStarting epoch 28/50\n====================\nTraining Loss: 0.0029\nValidation Accuracy: 75.00%\n====================\nStarting epoch 29/50\n====================\nTraining Loss: 0.0019\nValidation Accuracy: 75.00%\n====================\nStarting epoch 30/50\n====================\nTraining Loss: 0.0009\nValidation Accuracy: 75.50%\n====================\nStarting epoch 31/50\n====================\nTraining Loss: 0.0007\nValidation Accuracy: 75.00%\n====================\nStarting epoch 32/50\n====================\nTraining Loss: 0.0003\nValidation Accuracy: 74.50%\n====================\nStarting epoch 33/50\n====================\nTraining Loss: 0.0003\nValidation Accuracy: 75.00%\n====================\nStarting epoch 34/50\n====================\nTraining Loss: 0.0002\nValidation Accuracy: 75.00%\n====================\nStarting epoch 35/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 75.00%\n====================\nStarting epoch 36/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 75.00%\n====================\nStarting epoch 37/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 75.00%\n====================\nStarting epoch 38/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 75.00%\n====================\nStarting epoch 39/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 75.50%\n====================\nStarting epoch 40/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 75.00%\n====================\nStarting epoch 41/50\n====================\nTraining Loss: 0.0001\nValidation Accuracy: 75.50%\n====================\nStarting epoch 42/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 75.00%\n====================\nStarting epoch 43/50\n====================\nTraining Loss: 0.0000\nValidation Accuracy: 75.50%\n====================\nStarting epoch 44/50\n====================\n","output_type":"stream"}]},{"cell_type":"code","source":"def test(model, dataloader, criterion, device):\n    model.eval()  # Переводим модель в режим оценки (без обновления весов)\n\n    correct = 0\n    total = 0\n    y_pred = []\n\n    with torch.no_grad():\n        for val_step, (images, labels) in enumerate(dataloader):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            y_pred.extend(predicted.cpu().numpy())\n    accuracy = correct / total\n    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n\n    model.train()  # Возвращаем модель в режим обучения\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:12:39.376704Z","iopub.execute_input":"2024-03-13T18:12:39.377610Z","iopub.status.idle":"2024-03-13T18:12:39.385917Z","shell.execute_reply.started":"2024-03-13T18:12:39.377574Z","shell.execute_reply":"2024-03-13T18:12:39.384767Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"y_pred_test = test(googlenet, test_dataloader, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:12:44.030602Z","iopub.execute_input":"2024-03-13T18:12:44.031441Z","iopub.status.idle":"2024-03-13T18:12:45.116762Z","shell.execute_reply.started":"2024-03-13T18:12:44.031406Z","shell.execute_reply":"2024-03-13T18:12:45.115817Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Test Accuracy: 82.42%\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import precision_score, \\\n    recall_score, confusion_matrix, classification_report, \\\n    accuracy_score, f1_score\n\nprint ('\\n clasification report:\\n', classification_report(y_test, y_pred_test))\n\nprint('Матрица несоответствий для тестовой выборки:\\n')\nfig, ax = plt.subplots(figsize=(5, 5))\ndisp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test))\ndisp.plot(cmap = 'Blues', ax=ax);","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:12:52.025003Z","iopub.execute_input":"2024-03-13T18:12:52.025378Z","iopub.status.idle":"2024-03-13T18:12:52.325195Z","shell.execute_reply.started":"2024-03-13T18:12:52.025350Z","shell.execute_reply":"2024-03-13T18:12:52.324233Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"\n clasification report:\n               precision    recall  f1-score   support\n\n           0       0.79      0.91      0.85        97\n           1       0.87      0.73      0.79        85\n\n    accuracy                           0.82       182\n   macro avg       0.83      0.82      0.82       182\nweighted avg       0.83      0.82      0.82       182\n\nМатрица несоответствий для тестовой выборки:\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x500 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(googlenet.state_dict(), 'googlenet_new.pt')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T18:13:05.668504Z","iopub.execute_input":"2024-03-13T18:13:05.669493Z","iopub.status.idle":"2024-03-13T18:13:05.769074Z","shell.execute_reply.started":"2024-03-13T18:13:05.669458Z","shell.execute_reply":"2024-03-13T18:13:05.768146Z"},"trusted":true},"execution_count":41,"outputs":[]}]}